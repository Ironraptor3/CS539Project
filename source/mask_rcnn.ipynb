{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cabroderick/ML-AM-MQP/blob/main/mask_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4VO3uF19i5B"
   },
   "source": [
    "**Testing Mask-RCNN on sample dataset provided from ME team**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7bd8Qd1sqK9",
    "outputId": "d4c7c7dc-3163-42f4-ed54-8bb57e955a42"
   },
   "outputs": [],
   "source": [
    "# uninstall improper package versions\n",
    "!pip uninstall keras -y\n",
    "!pip uninstall keras-nightly -y\n",
    "!pip uninstall keras-Preprocessing -y\n",
    "!pip uninstall keras-vis -y\n",
    "!pip uninstall tensorflow -y\n",
    "!pip uninstall h5py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-gPN3riwtmAS",
    "outputId": "76f37b30-ba61-446d-cb5e-c3c669a0726a"
   },
   "outputs": [],
   "source": [
    "# reinstall with proper versions\n",
    "!pip install tensorflow==1.13.1\n",
    "!pip install keras==2.0.8\n",
    "!pip install h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6y9RJx8fFSD",
    "outputId": "3ef23dfa-ffe4-4b1e-ec85-0139db1a9708"
   },
   "outputs": [],
   "source": [
    "# import mask rcnn and set up\n",
    "%cd\n",
    "!git clone https://github.com/matterport/Mask_RCNN.git\n",
    "%cd Mask_RCNN/\n",
    "!python setup.py install\n",
    "!pip show mask-rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMYTaei-TXMB",
    "outputId": "2d9f4430-e412-4419-982f-c0dd01cc556a"
   },
   "outputs": [],
   "source": [
    "# import training data\n",
    "%cd\n",
    "!git clone https://github.com/cabroderick/ML-AM-MQP\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# list data contents\n",
    "%cd '~/ML-AM-MQP/Data/Trial/H6'\n",
    "!ls\n",
    "%cd '~/ML-AM-MQP/Data/Trial/Labeled H6'\n",
    "!ls\n",
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5NBHWwrrXCl",
    "outputId": "8f81c284-21cb-4fd3-dd08-4c79552808c6"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from cv2 import imread\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NCRBaSTI-SUM",
    "outputId": "354b313e-c737-4338-c3f1-abc35d701f9f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# configure network\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    NAME = \"object\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    # number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 2\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    LEARNING_RATE = .001\n",
    "\n",
    "config = CustomConfig()\n",
    "\n",
    "# set up dataset\n",
    "\n",
    "class AMDataset(utils.Dataset):\n",
    "  def load_dataset(self, validation=False):\n",
    "    IMAGES_DIR = \"/root/ML-AM-MQP/Data/Trial/H6/\"\n",
    "    ANNOTATIONS_DIR = '/root/ML-AM-MQP/Data/Trial/Labeled H6/'\n",
    "    IMG_WIDTH = 1280\n",
    "    IMG_HEIGHT = 1024\n",
    "\n",
    "    self.add_class('dataset', 1, 'gas porosity')\n",
    "    self.add_class('dataset', 2, 'lack of fusion porosity')\n",
    "\n",
    "    val_images = 5 # keeps track of images to reserve for validation set\n",
    "    total_images = len(os.listdir(IMAGES_DIR))\n",
    "    for filename in os.listdir(IMAGES_DIR):\n",
    "      if validation and val_images > 0:\n",
    "        val_images -=1\n",
    "        continue\n",
    "      if (not validation) and val_images < total_images:\n",
    "        val_images += 1\n",
    "        continue\n",
    "\n",
    "      image_id = filename[:-4]\n",
    "      image_path = IMAGES_DIR + image_id + '.tif'\n",
    "      annotation_path = ANNOTATIONS_DIR + image_id + '_labeled.json'\n",
    "      self.add_image('dataset',\n",
    "                     image_id=image_id, \n",
    "                     path=image_path, \n",
    "                     annotation=annotation_path,\n",
    "                     width=IMG_WIDTH,\n",
    "                     height=IMG_HEIGHT)\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    class_ids = list() # list of class ids corresponding to each mask in the mask list\n",
    "    image_info = self.image_info[image_id] # extract image info from data added earlier\n",
    "\n",
    "    width = image_info['width']\n",
    "    height = image_info['height']\n",
    "    path = image_info['annotation']\n",
    "\n",
    "    masks_index = 0 # keep track of index for use in masks\n",
    "\n",
    "    boxes = self.extract_boxes(path) # extract mask data from json file\n",
    "    masks = np.zeros([height, width, len(boxes)], dtype='uint8') # initialize array of masks for each bounding box\n",
    "    for i in range(len(boxes)):\n",
    "      box = boxes[i]\n",
    "      for key in box:\n",
    "        if (box[key]): # make sure box is not empty\n",
    "          col_s, col_e = int(box[key][0][0]), int(box[key][0][1])\n",
    "          row_s, row_e = int(box[key][1][0]), int(box[key][1][1])\n",
    "          masks[row_s:row_e, col_s:col_e, masks_index] = 1\n",
    "          masks_index += 1\n",
    "          class_ids.append(self.class_names.index(key))\n",
    "\n",
    "    return masks, np.array(class_ids)\n",
    "\n",
    "  def extract_boxes(self, filename): # helper to extract bounding boxes from json\n",
    "      f = open(filename,)\n",
    "      data = json.load(f)\n",
    "\n",
    "      boxes = [] # store box coordinates in a dictionary corresponding to labels\n",
    "\n",
    "      for i in data['shapes']:\n",
    "        if i['shape_type'] == 'rectangle':\n",
    "          box = {'gas porosity': [], 'lack of fusion porosity': []}\n",
    "          label = i['label']\n",
    "          box[label] = i['points']\n",
    "          boxes.append(box)\n",
    " \n",
    "      return boxes\n",
    "\n",
    "# set up train and validation data\n",
    "\n",
    "dataset_train = AMDataset()\n",
    "dataset_train.load_dataset(validation=False)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = AMDataset()\n",
    "dataset_val.load_dataset(validation=True)\n",
    "dataset_val.prepare()\n",
    "\n",
    "# configure model and load coco weights\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5\", \"mask_rcnn_coco.h5\")\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=CustomConfig())\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# train model\n",
    "model.train(train_dataset=dataset_train,\n",
    "            val_dataset=dataset_val,\n",
    "            learning_rate=.001,\n",
    "            epochs=1,\n",
    "            layers='heads')\n",
    "\n",
    "# save training results to external file\n",
    "model_path = 'custom_maskrcnn_weights.h5'\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "Ot2h4fZFxZWo",
    "outputId": "a58f8364-fe4e-40e1-eb70-afc7aa4a27da"
   },
   "outputs": [],
   "source": [
    "# model_path = 'custom_maskrcnn_weights.h5'\n",
    "# model.keras_model.save_weights(model_path)\n",
    "\n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, boxes_list):\n",
    "     # load the image\n",
    "     data = pyplot.imread(filename)\n",
    "     # plot the image\n",
    "     pyplot.imshow(data)\n",
    "     # get the context for drawing boxes\n",
    "     ax = pyplot.gca()\n",
    "     # plot each box\n",
    "     for box in boxes_list:\n",
    "          # get coordinates\n",
    "          y1, x1, y2, x2 = box\n",
    "          # calculate width and height of the box\n",
    "          width, height = x2 - x1, y2 - y1\n",
    "          # create the shape\n",
    "          rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "          # draw the box\n",
    "          ax.add_patch(rect)\n",
    "     # show the plot\n",
    "     pyplot.show()\n",
    "\n",
    "# load photograph\n",
    "img = load_img('/root/ML-AM-MQP/Data/Trial/H6/A1H6COL_10X_BF_ZUYL_27.tif')\n",
    "img = img_to_array(img)\n",
    "\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=CustomConfig())\n",
    "model.load_weights('/root/ML-AM-MQP/Data/Trial/Labeled H6/custom_maskrcnn_weights.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# make prediction\n",
    "results = model.detect(img, verbose=0)\n",
    "# visualize the results\n",
    "draw_image_with_boxes('/root/ML-AM-MQP/Data/Trial/H6/A1H6COL_10X_BF_ZUYL_27.tif', results[0]['rois'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "VIg90Xo3qY8C",
    "outputId": "20d00788-e6c7-4e76-8384-0a03184a8de1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# example of inference with a pre-trained coco model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    " \n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, boxes_list):\n",
    "     # load the image\n",
    "     data = pyplot.imread(filename)\n",
    "     # plot the image\n",
    "     pyplot.imshow(data)\n",
    "     # get the context for drawing boxes\n",
    "     ax = pyplot.gca()\n",
    "     # plot each box\n",
    "     for box in boxes_list:\n",
    "          # get coordinates\n",
    "          y1, x1, y2, x2 = box\n",
    "          # calculate width and height of the box\n",
    "          width, height = x2 - x1, y2 - y1\n",
    "          # create the shape\n",
    "          rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "          # draw the box\n",
    "          ax.add_patch(rect)\n",
    "     # show the plot\n",
    "     pyplot.show()\n",
    " \n",
    "# define the test configuration\n",
    "class TestConfig(Config):\n",
    "     NAME = \"test\"\n",
    "     GPU_COUNT = 1\n",
    "     IMAGES_PER_GPU = 1\n",
    "     NUM_CLASSES = 3\n",
    " \n",
    "# define the model\n",
    "rcnn = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n",
    "# load coco model weights\n",
    "rcnn.load_weights('/root/ML-AM-MQP/Data/Trial/Labeled H6/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "rcnn.load_weights('/root/ML-AM-MQP/Data/Trial/Labeled H6/custom_maskrcnn_weights.h5', by_name=True)\n",
    "# load photograph\n",
    "img = load_img('/root/ML-AM-MQP/Data/Trial/H6/A1H6COL_10X_BF_ZUYL_22.tif')\n",
    "img = img_to_array(img)\n",
    "# make prediction\n",
    "results = rcnn.detect([img], verbose=0)\n",
    "# visualize the results\n",
    "draw_image_with_boxes('/root/ML-AM-MQP/Data/Trial/H6/A1H6COL_10X_BF_ZUYL_22.tif', results[0]['rois'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of mask_rcnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
