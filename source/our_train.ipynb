{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Mask-RCNN setup**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uninstall improper package versions\n",
    "!pip uninstall keras -y\n",
    "!pip uninstall keras-nightly -y\n",
    "!pip uninstall keras-Preprocessing -y\n",
    "!pip uninstall keras-vis -y\n",
    "!pip uninstall tensorflow -y\n",
    "!pip uninstall h5py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reinstall with proper versions\n",
    "!pip install tensorflow==1.13.1\n",
    "!pip install keras==2.0.8\n",
    "!pip install h5py==2.10.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import mask rcnn and set up\n",
    "%cd\n",
    "!git clone https://github.com/matterport/Mask_RCNN.git\n",
    "%cd Mask_RCNN/\n",
    "!python setup.py install\n",
    "!pip show mask-rcnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mrcnn import utils\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "import skimage.draw\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "# Configuration\n",
    "######################################\n",
    "class CustomConfig(Config):\n",
    "    NAME = \"custom_mcrnn\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 3 # ?? classes + background\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    VALIDATION_STEPS = 5\n",
    "    LEARNING_RATE = .001\n",
    "    BATCH_SIZE = 10\n",
    "\n",
    "config = CustomConfig()\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Dataset\n",
    "#######################################\n",
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    # define constants\n",
    "    DATASET_DIR = 'data' # directory where train images can be found\n",
    "    BASE_ANNOTATIONS_FILE = 'data/annotations.json' # file with annotations\n",
    "\n",
    "    TRAIN_TEST_SPLIT = .8 # proportion of images to use for training set, remainder will be reserved for validation\n",
    "    CLASSES = [] # all annotation classes, to generate from the json\n",
    "\n",
    "    def load_dataset(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Balloon dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "        #add all new classes\n",
    "        for i, c in enumerate(CLASSES):\n",
    "            self.add_class(\"object\", i, c)\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(DATASET_DIR, subset)\n",
    "        annotations = json.load(open(BASE_ANNOTATIONS_FILE))\n",
    "\n",
    "        #go through each image\n",
    "        for a in annotations.imgs:\n",
    "            for instance in a.objects:\n",
    "                if instance.polygon:\n",
    "                    polygons = instance.polygon\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, a['path'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"sign\",\n",
    "                image_id=a[\"id\"],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"balloon\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            all_x, all_y = zip(*p) #unzip the list\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(all_y, all_x)\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Training\n",
    "#######################################\n",
    "\n",
    "# set up train and validation data\n",
    "\n",
    "dataset_train = CustomDataset()\n",
    "dataset_train.load_dataset(validation=False)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = CustomDataset()\n",
    "dataset_val.load_dataset(validation=True)\n",
    "dataset_val.prepare()\n",
    "\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5\", \"mask_rcnn_coco.h5\")\n",
    "model = MaskRCNN(mode='training', model_dir='./'+sys.argv[1]+'/', config=CustomConfig())\n",
    "\n",
    "if len(sys.argv) > 2: # optionally load pre-trained weights - COCO\n",
    "    model.load_weights(sys.argv[2], by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# print summary\n",
    "print(model.keras_model.summary())\n",
    "\n",
    "# train model\n",
    "model.train(train_dataset=dataset_train,\n",
    "            val_dataset=dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='heads')\n",
    "\n",
    "# save training results to external file\n",
    "model.keras_model.save_weights(sys.argv[1]+'.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}